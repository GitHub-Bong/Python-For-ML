{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for 문 2번 쓸 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_gradient(x, y, theta, iterations=100000, alpha=0.01):\n",
    "    \n",
    "    m = y.size\n",
    "    cost_history = []\n",
    "    theta_history = []\n",
    "    \n",
    "    for _ in range(iterations):        \n",
    "        predictions = x.dot(theta)\n",
    "        \n",
    "        for i in range(theta.size):\n",
    "            partial_marginal = x[:, i]\n",
    "            errors_xi = (predictions - y) * partial_marginal\n",
    "            theta[i] = theta[i] - alpha * (1.0 / m) * errors_xi.sum()\n",
    "        \n",
    "        if _ % 1000 == 0:\n",
    "            theta_history.append(theta)\n",
    "            cost_history.append(compute_cost(x, y, theta))\n",
    "\n",
    "    return theta, np.array(cost_history), np.array(theta_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(x, y, theta):\n",
    "    '''\n",
    "    Comput cost for linear regression\n",
    "    '''\n",
    "    #Number of training samples\n",
    "    m = y.size\n",
    "    predictions = x.dot(theta)\n",
    "    sqErrors = (predictions - y)\n",
    "\n",
    "    J = (1.0 / (2 * m)) * sqErrors.T.dot(sqErrors)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for 문 1번 쓸 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, theta, alpha, m, numIterations):\n",
    "    xTrans = x.transpose():\n",
    "    theta_list = []\n",
    "    cost_lit = []\n",
    "    for i in range(0, numIterations):\n",
    "        hypothesis = np.dot(x, theta)\n",
    "        loss = hypothesis - y\n",
    "        \n",
    "        cost = np.sum(loss ** 2) / (2 * m)\n",
    "        gradient = np.dot(xTrans, loss)/ m\n",
    "        \n",
    "        theta = theta - alpha * gradient\n",
    "        if i % 250 == 0:\n",
    "            theta_list.append(theta)\n",
    "            cost_list.append(cost)\n",
    "    return theta, np.array(theta_list), cost_list\n",
    "\n",
    "# m denotes the number of examples here, not the number of features\n",
    "m, n = np.shape(x)\n",
    "numIterations = 5000\n",
    "alpha = 0.0005\n",
    "theta = np.ones(n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
